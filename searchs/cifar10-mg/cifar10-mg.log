07/14 09:17:20 AM | 
07/14 09:17:20 AM | Parameters:
07/14 09:17:20 AM | ALPHA_LR=0.0012
07/14 09:17:20 AM | ALPHA_WEIGHT_DECAY=0.001
07/14 09:17:20 AM | BATCH_SIZE=256
07/14 09:17:20 AM | DATA_PATH=./data/
07/14 09:17:20 AM | DATASET=cifar10
07/14 09:17:20 AM | EPOCHS=1
07/14 09:17:20 AM | GPUS=[0, 1, 2, 3]
07/14 09:17:20 AM | INIT_CHANNELS=16
07/14 09:17:20 AM | LAYERS=8
07/14 09:17:20 AM | NAME=cifar10-mg
07/14 09:17:20 AM | PATH=searchs/cifar10-mg
07/14 09:17:20 AM | PLOT_PATH=searchs/cifar10-mg/plots
07/14 09:17:20 AM | PRINT_FREQ=10
07/14 09:17:20 AM | SEED=2
07/14 09:17:20 AM | W_GRAD_CLIP=5.0
07/14 09:17:20 AM | W_LR=0.1
07/14 09:17:20 AM | W_LR_MIN=0.004
07/14 09:17:20 AM | W_MOMENTUM=0.9
07/14 09:17:20 AM | W_WEIGHT_DECAY=0.0003
07/14 09:17:20 AM | WORKERS=16
07/14 09:17:20 AM | 
07/14 09:17:20 AM | Logger is set - training start
07/14 09:18:04 AM | 
07/14 09:18:04 AM | Parameters:
07/14 09:18:04 AM | ALPHA_LR=0.0012
07/14 09:18:04 AM | ALPHA_WEIGHT_DECAY=0.001
07/14 09:18:04 AM | BATCH_SIZE=256
07/14 09:18:04 AM | DATA_PATH=./data/
07/14 09:18:04 AM | DATASET=cifar10
07/14 09:18:04 AM | EPOCHS=1
07/14 09:18:04 AM | GPUS=[0, 1, 2, 3, 4, 5, 6, 7]
07/14 09:18:04 AM | INIT_CHANNELS=16
07/14 09:18:04 AM | LAYERS=8
07/14 09:18:04 AM | NAME=cifar10-mg
07/14 09:18:04 AM | PATH=searchs/cifar10-mg
07/14 09:18:04 AM | PLOT_PATH=searchs/cifar10-mg/plots
07/14 09:18:04 AM | PRINT_FREQ=10
07/14 09:18:04 AM | SEED=2
07/14 09:18:04 AM | W_GRAD_CLIP=5.0
07/14 09:18:04 AM | W_LR=0.1
07/14 09:18:04 AM | W_LR_MIN=0.004
07/14 09:18:04 AM | W_MOMENTUM=0.9
07/14 09:18:04 AM | W_WEIGHT_DECAY=0.0003
07/14 09:18:04 AM | WORKERS=16
07/14 09:18:04 AM | 
07/14 09:18:04 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/14 09:23:36 AM | 
07/14 09:23:36 AM | Parameters:
07/14 09:23:36 AM | ALPHA_LR=0.0012
07/14 09:23:36 AM | ALPHA_WEIGHT_DECAY=0.001
07/14 09:23:36 AM | BATCH_SIZE=256
07/14 09:23:36 AM | DATA_PATH=./data/
07/14 09:23:36 AM | DATASET=cifar10
07/14 09:23:36 AM | EPOCHS=1
07/14 09:23:36 AM | GPUS=[0, 1, 2, 3, 4, 5, 6, 7]
07/14 09:23:36 AM | INIT_CHANNELS=16
07/14 09:23:36 AM | LAYERS=8
07/14 09:23:36 AM | NAME=cifar10-mg
07/14 09:23:36 AM | PATH=searchs/cifar10-mg
07/14 09:23:36 AM | PLOT_PATH=searchs/cifar10-mg/plots
07/14 09:23:36 AM | PRINT_FREQ=10
07/14 09:23:36 AM | SEED=2
07/14 09:23:36 AM | W_GRAD_CLIP=5.0
07/14 09:23:36 AM | W_LR=0.1
07/14 09:23:36 AM | W_LR_MIN=0.004
07/14 09:23:36 AM | W_MOMENTUM=0.9
07/14 09:23:36 AM | W_WEIGHT_DECAY=0.0003
07/14 09:23:36 AM | WORKERS=16
07/14 09:23:36 AM | 
07/14 09:23:36 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/14 09:27:32 AM | Train: [ 1/1] Step 000/028 Loss 3.505 Prec@(1,5) (1.0%, 19.0%)
07/14 09:54:34 AM | 
07/14 09:54:34 AM | Parameters:
07/14 09:54:34 AM | ALPHA_LR=0.0012
07/14 09:54:34 AM | ALPHA_WEIGHT_DECAY=0.001
07/14 09:54:34 AM | BATCH_SIZE=256
07/14 09:54:34 AM | DATA_PATH=./data/
07/14 09:54:34 AM | DATASET=cifar10
07/14 09:54:34 AM | EPOCHS=1
07/14 09:54:34 AM | GPUS=[0, 1, 2, 3]
07/14 09:54:34 AM | INIT_CHANNELS=16
07/14 09:54:34 AM | LAYERS=8
07/14 09:54:34 AM | NAME=cifar10-mg
07/14 09:54:34 AM | PATH=searchs/cifar10-mg
07/14 09:54:34 AM | PLOT_PATH=searchs/cifar10-mg/plots
07/14 09:54:34 AM | PRINT_FREQ=10
07/14 09:54:34 AM | SEED=2
07/14 09:54:34 AM | W_GRAD_CLIP=5.0
07/14 09:54:34 AM | W_LR=0.1
07/14 09:54:34 AM | W_LR_MIN=0.004
07/14 09:54:34 AM | W_MOMENTUM=0.9
07/14 09:54:34 AM | W_WEIGHT_DECAY=0.0003
07/14 09:54:34 AM | WORKERS=16
07/14 09:54:34 AM | 
07/14 09:54:34 AM | Logger is set - training start
####### ALPHA #######
# Alpha - normal
tensor([[0.1249, 0.1252, 0.1249, 0.1249, 0.1249, 0.1252, 0.1249, 0.1250],
        [0.1249, 0.1251, 0.1250, 0.1250, 0.1252, 0.1249, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1249, 0.1253, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1249],
        [0.1251, 0.1247, 0.1249, 0.1253, 0.1248, 0.1249, 0.1251, 0.1253],
        [0.1250, 0.1250, 0.1249, 0.1251, 0.1252, 0.1250, 0.1251, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251, 0.1249, 0.1251],
        [0.1250, 0.1249, 0.1251, 0.1249, 0.1249, 0.1253, 0.1252, 0.1248],
        [0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1250, 0.1251, 0.1250],
        [0.1250, 0.1251, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1248]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1250, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249, 0.1252],
        [0.1250, 0.1252, 0.1252, 0.1248, 0.1250, 0.1249, 0.1248, 0.1251],
        [0.1251, 0.1251, 0.1250, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1250, 0.1253, 0.1251, 0.1251, 0.1247, 0.1249],
        [0.1251, 0.1251, 0.1252, 0.1249, 0.1249, 0.1251, 0.1250, 0.1249]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)

# Alpha - reduce
tensor([[0.1248, 0.1249, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1251],
        [0.1250, 0.1248, 0.1249, 0.1252, 0.1249, 0.1250, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1249, 0.1252, 0.1249, 0.1250, 0.1250, 0.1249, 0.1250],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1249, 0.1250, 0.1251],
        [0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1251, 0.1247, 0.1249, 0.1252, 0.1252, 0.1249, 0.1251, 0.1249],
        [0.1250, 0.1250, 0.1250, 0.1251, 0.1253, 0.1249, 0.1249, 0.1248],
        [0.1250, 0.1252, 0.1250, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249],
        [0.1250, 0.1251, 0.1251, 0.1249, 0.1248, 0.1251, 0.1250, 0.1250]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
tensor([[0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250],
        [0.1252, 0.1249, 0.1251, 0.1251, 0.1250, 0.1249, 0.1249, 0.1249],
        [0.1249, 0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1252],
        [0.1250, 0.1249, 0.1250, 0.1251, 0.1250, 0.1251, 0.1250, 0.1249],
        [0.1249, 0.1251, 0.1250, 0.1251, 0.1248, 0.1251, 0.1249, 0.1251]],
       device='cuda:0', grad_fn=<SoftmaxBackward>)
#####################
07/14 09:55:49 AM | Train: [ 1/1] Step 000/028 Loss 3.533 Prec@(1,5) (3.0%, 16.0%)
07/14 10:05:22 AM | Train: [ 1/1] Step 010/028 Loss 3.485 Prec@(1,5) (3.4%, 16.5%)
07/14 10:14:44 AM | Train: [ 1/1] Step 020/028 Loss 3.494 Prec@(1,5) (2.6%, 14.5%)
07/14 10:22:10 AM | Train: [ 1/1] Step 028/028 Loss 3.494 Prec@(1,5) (2.7%, 14.1%)
07/14 10:22:10 AM | Train: [ 1/1] Final Prec@1 2.7334%
07/14 10:59:27 AM | 
07/14 10:59:27 AM | Parameters:
07/14 10:59:27 AM | ALPHA_LR=0.0012
07/14 10:59:27 AM | ALPHA_WEIGHT_DECAY=0.001
07/14 10:59:27 AM | BATCH_SIZE=256
07/14 10:59:27 AM | DATA_PATH=./data/
07/14 10:59:27 AM | DATASET=cifar10
07/14 10:59:27 AM | EPOCHS=1
07/14 10:59:27 AM | GPUS=[0, 1, 2, 3]
07/14 10:59:27 AM | INIT_CHANNELS=16
07/14 10:59:27 AM | LAYERS=8
07/14 10:59:27 AM | NAME=cifar10-mg
07/14 10:59:27 AM | PATH=searchs/cifar10-mg
07/14 10:59:27 AM | PLOT_PATH=searchs/cifar10-mg/plots
07/14 10:59:27 AM | PRINT_FREQ=10
07/14 10:59:27 AM | SEED=2
07/14 10:59:27 AM | W_GRAD_CLIP=5.0
07/14 10:59:27 AM | W_LR=0.1
07/14 10:59:27 AM | W_LR_MIN=0.004
07/14 10:59:27 AM | W_MOMENTUM=0.9
07/14 10:59:27 AM | W_WEIGHT_DECAY=0.0003
07/14 10:59:27 AM | WORKERS=16
07/14 10:59:27 AM | 
07/14 10:59:27 AM | Logger is set - training start
